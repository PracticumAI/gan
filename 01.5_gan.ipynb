{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true)\n",
    "***\n",
    "# *Practicum AI:* GAN - The Final Model\n",
    "\n",
    "This exercise was adapted from Baig et al. (2020) <i> The Deep Learning Workshop</i> from <a href=\"https://www.packtpub.com/product/the-deep-learning-workshop/9781839219856\">Packt Publishers</a> (Exercise 7.04, page 348).\n",
    "\n",
    "In this exercise, we will build and train the GAN using the method described in the previous section.\n",
    "\n",
    "To finish this exercise, follow these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px;margin-bottom: 20px;border: thin solid #30335D;border-left-width: 10px;background-color: #fff\"><strong>Note:</strong> As this exercise builds on and extends exercise 7.03, these setup sections come from that earlier section. </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the requisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required library functions\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from numpy.random import randn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define a function to generate real samples\n",
    "This function is equivalent to the one created in exercise **01.2_generate_data** that generates a data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realData(loc, batch):\n",
    "    '''Function to generate real samples. '''\n",
    "    \n",
    "    # loc is the random location or mean around which samples are centred\n",
    "    # Generate numbers to right of the random point\n",
    "    xr = np.arange(loc, loc + (0.1 * batch / 2), 0.1)\n",
    "    xr = xr[0:int(batch / 2)]\n",
    "    \n",
    "    # Generate numbers to left of the random point\n",
    "    xl = np.arange(loc - (0.1 * batch / 2), loc, 0.1)\n",
    "    \n",
    "    # Concatenating both these series \n",
    "    X1 = np.concatenate((xl, xr))\n",
    "    \n",
    "    # Second dependent variable\n",
    "    X2 = np.sin(X1)\n",
    "    \n",
    "    # Reshaping both the variables and then concatenating them to an array of independent variables\n",
    "    X1 = X1.reshape(batch, 1)\n",
    "    X2 = X2.reshape(batch, 1)    \n",
    "    X  = np.concatenate((X1, X2),axis = 1)\n",
    "    \n",
    "    # Generating the labels for the real data set which is 'ones'\n",
    "    y = np.ones((batch, 1)) \n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define a function to generate inputs for the generator network\n",
    "This function generates a fake dataset sampled from the random distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fakeInputs(batch, infeats):\n",
    "    '''Function to generate inputs for the generator function. '''\n",
    "    \n",
    "    # Sample data points equal to (batch x input feature size) from a random distribution\n",
    "    genInput = randn(infeats * batch)\n",
    "    \n",
    "    # Reshape the input \n",
    "    X = genInput.reshape(batch ,infeats)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define a function to create the generator network\n",
    "This function is the same as the one we built in exercise **01.3_generator** to create a generator network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genModel(infeats, outfeats):\n",
    "    '''Function which instantiates the generator model. '''\n",
    "    \n",
    "    # Define and instantiate the Generator model\n",
    "    Genmodel = Sequential()\n",
    "    Genmodel.add(Dense(32,activation = 'linear', kernel_initializer = 'he_uniform', input_dim = infeats))\n",
    "    Genmodel.add(Dense(32,activation = 'relu', kernel_initializer = 'he_uniform'))    \n",
    "    Genmodel.add(Dense(64,activation = 'elu', kernel_initializer = 'he_uniform'))    \n",
    "    Genmodel.add(Dense(32,activation = 'elu', kernel_initializer = 'he_uniform'))    \n",
    "    Genmodel.add(Dense(32,activation = 'selu', kernel_initializer = 'he_uniform'))\n",
    "    Genmodel.add(Dense(outfeats,activation = 'selu'))\n",
    "    \n",
    "    return Genmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Define a function to create fake samples using the generator network\n",
    "This function takes the random data distribution as input and generates the fake distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create fake samples using the generator model\n",
    "def fakedataGenerator(Genmodel, batch,infeats):\n",
    "    ''' Function to create fake samples using the generator model. '''\n",
    "    \n",
    "    # First generate the inputs to the model\n",
    "    genInputs = fakeInputs(batch,infeats)\n",
    "    \n",
    "    # Use these inputs inside the generator model to generate fake distribution\n",
    "    X_fake = Genmodel.predict(genInputs)\n",
    "    \n",
    "    # Generate the labels of fake data set\n",
    "    y_fake = np.zeros((batch,1))\n",
    "    \n",
    "    return X_fake, y_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define the global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments like batch size,input feature size and output feature size\n",
    "\n",
    "batch    = 128\n",
    "infeats  = 10\n",
    "outfeats = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Define a function to create the discriminator\n",
    "This function is the same as the one we built in exercise **01.4_discriminator** to create a discriminator network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discModel(outfeats):\n",
    "    ''' Function which instantiates the discriminator model. '''\n",
    "    Discmodel = Sequential()\n",
    "    Discmodel.add(Dense(16, activation = 'relu',kernel_initializer = 'he_uniform',input_dim=outfeats))\n",
    "    Discmodel.add(Dense(16,activation = 'relu' ,kernel_initializer = 'he_uniform'))\n",
    "    Discmodel.add(Dense(16,activation = 'relu' ,kernel_initializer = 'he_uniform'))    \n",
    "    Discmodel.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    # Compiling the model\n",
    "    Discmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])    \n",
    "    return Discmodel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Print a summary of the discriminator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 609\n",
      "Trainable params: 609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the summary of the discriminator model\n",
    "\n",
    "Discmodel = discModel(outfeats)\n",
    "Discmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Invoke the generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 6,722\n",
      "Trainable params: 6,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the generator model by calling the genModel() function.\n",
    "\n",
    "Genmodel = genModel(infeats, outfeats)\n",
    "Genmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Visualize the fake data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the initial fake data\n",
    "x_fake, _ = fakedataGenerator(Genmodel, batch, infeats)\n",
    "\n",
    "# Plotting the fake data using pyplot\n",
    "pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color = 'blue')\n",
    "\n",
    "# Adding x and y labels\n",
    "pyplot.xlabel('Feature 1 of the distribution')\n",
    "pyplot.ylabel('Feature 2 of the distribution')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding plot shows that the data distribution is quite random. We can convert this random data into a form similar to the sine wave, which was our real data distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Define a function to create the GAN model\n",
    "Function ganModel is just a wrapper for the generator and discriminator models defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganModel(Genmodel,Discmodel):\n",
    "    ''' Function which instantiates the GAN model.'''\n",
    "    \n",
    "    # First define that discriminator model cannot be trained\n",
    "    Discmodel.trainable = False\n",
    "    Ganmodel = Sequential()\n",
    "    \n",
    "    # First adding the generator model\n",
    "    Ganmodel.add(Genmodel)\n",
    "    \n",
    "    # Next adding the discriminator model without training the parameters\n",
    "    Ganmodel.add(Discmodel)\n",
    "    \n",
    "    # Compile the model for loss to optimise the Generator model\n",
    "    Ganmodel.compile(loss='binary_crossentropy',optimizer = 'adam')  \n",
    "    \n",
    "    return Ganmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Instantiate the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the gan model\n",
    "gan_model = ganModel(Genmodel,Discmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Print summary of the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of the GAN model\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Define the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of epochs\n",
    "nEpochs = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Train the GAN network\n",
    "\n",
    "The following are the steps in the GAN model training process:\n",
    "* 1. Generate a random number and then generate a batch of real samples and their labels.\n",
    "* 2. Generate a batch of fake samples and their labels.\n",
    "* 3. Train the discriminator model using the `train_on_batch()` function using the batch of real samples and fake samples.\n",
    "* 4. Generate another batch of fake samples to train the GAN model.\n",
    "* 5. Generate the labels for the fake samples meant to fool the discriminator.\n",
    "* 6. Train the GAN model using the `train_on_batch()` function using the new fake samples and their labels.\n",
    "* 7. Repeat step 1 to 6 for the number of epochs we want the training to run for. This can be done through a for loop over the number of epochs.\n",
    "* 8. At every intermediate step, we calculate the accuracy of the model on the fake samples and real samples using the `evaluate()` function. We also generate output plots at certain epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real accuracy:0.0,Fake accuracy:0.984375\n",
      "Real accuracy:1.0,Fake accuracy:0.9609375\n",
      "Real accuracy:1.0,Fake accuracy:0.96875\n",
      "Real accuracy:1.0,Fake accuracy:0.984375\n",
      "Real accuracy:1.0,Fake accuracy:0.96875\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN network\n",
    "for i in range(nEpochs):\n",
    "    # Generate the random number for generating real samples\n",
    "    loc = np.random.normal(3,1,1)\n",
    "    \n",
    "    # Generate samples equal to the bath size from the real distribution\n",
    "    x_real, y_real = realData(loc,batch)\n",
    "    \n",
    "    # Generate fake samples using the fake data generator function\n",
    "    x_fake, y_fake = fakedataGenerator(Genmodel,batch,infeats)\n",
    "    \n",
    "    # Train the  discriminator on the real samples\n",
    "    Discmodel.train_on_batch(x_real, y_real)\n",
    "    \n",
    "    # Train the discriminator on the fake samples\n",
    "    Discmodel.train_on_batch(x_fake, y_fake)\n",
    "    \n",
    "    # Generate new fake inputs for training the GAN network\n",
    "    x_gan = fakeInputs(batch, infeats)\n",
    "    \n",
    "    # Create labels of the fake examples as 1 to fool the discriminator\n",
    "    y_gan = np.ones((batch, 1))\n",
    "    \n",
    "    # Update the generator model through the discriminator model\n",
    "    gan_model.train_on_batch(x_gan, y_gan)\n",
    "    \n",
    "    # Print the accuracy measures on the real and fake data for every 2000 epochs\n",
    "    if (i) % 2000 == 0:\n",
    "        # Generate samples equal to the bath size from the real distribution\n",
    "        x_real, y_real = realData(loc,batch)\n",
    "        \n",
    "        # Evaluate Real distribution accuracy\n",
    "        _, realAccuracy = Discmodel.evaluate(x_real, y_real, verbose = 0)\n",
    "        \n",
    "        # Generate fake samples using the fake data generator function\n",
    "        x_fake,y_fake = fakedataGenerator(Genmodel,batch,infeats)\n",
    "        \n",
    "        # Evaluate fake distribution accuracy levels\n",
    "        _, fakeAccuracy = Discmodel.evaluate(x_fake, y_fake, verbose = 0)\n",
    "        \n",
    "        print('Real accuracy:{R},Fake accuracy:{F}'.format(R = realAccuracy, F = fakeAccuracy))\n",
    "        \n",
    "        # Scatter plot real and fake data points\n",
    "        pyplot.scatter(x_real[:, 0], x_real[:, 1], color = 'red')\n",
    "        pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color = 'blue')\n",
    "        pyplot.xlabel('Feature 1 of the distribution')\n",
    "        pyplot.ylabel('Feature 2 of the distribution')\n",
    "        \n",
    "        # Save plot to file\n",
    "        filename = 'GAN_Training_Plot%03d.png' % (i)\n",
    "        pyplot.savefig(filename)\n",
    "        pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "This exercise presented the entire process of building a GAN.  We learned what a GAN is, its components, and how they  work together to generate a plausible data distribution. You now have the knowledge to create GANs using your own data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.4.1",
   "language": "python",
   "name": "tensorflow-2.4.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
